{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "\n",
    "df1 = pd.read_csv(\"Bengaluru_House_Data.csv\")\n",
    "# df1.head()\n",
    "\n",
    "df1.shape\n",
    "\n",
    "## Data Cleanning Process\n",
    "\n",
    "testd =  df1.groupby('area_type').count()\n",
    "# testd\n",
    "\n",
    "df1.groupby('area_type')[\"area_type\"].agg(\"count\")  #shows the count of particular area types\n",
    "\n",
    "\n",
    "df2 = df1.drop([\"area_type\", \"society\", \"balcony\", \"availability\"], axis=\"columns\") # dropping unnecessary columns\n",
    "\n",
    "# df2.head()\n",
    "\n",
    "df2.isnull().sum() # counting the missing values for each column\n",
    "\n",
    "df3 = df2.dropna()  # droping the rows containing any null value\n",
    "# df3.shape\n",
    "\n",
    "df3.isnull().sum()\n",
    "\n",
    "# examining size column\n",
    "\n",
    "# df3['size'].unique()\n",
    "\n",
    "df3['bhk'] = df3['size'].apply(lambda x : int(x.split(\" \")[0]))\n",
    "\n",
    "# df3.head()\n",
    "\n",
    "# df3['bhk'].unique()\n",
    "\n",
    "# df3[df3[\"bhk\"] > 20]\n",
    "\n",
    "# examining total_sqft column\n",
    "# len(df3[\"total_sqft\"].unique())\n",
    "\n",
    "# df3[\"total_sqft\"].unique()\n",
    "\n",
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# checking the total sqft values which is not float\n",
    "# df3[~df3[\"total_sqft\"].apply(is_float)].head(10)\n",
    "\n",
    "def convert_sqft_to_num(x):\n",
    "    tokens = x.split(\"-\")\n",
    "    if len(tokens) == 2:\n",
    "        return (float(tokens[0]) + float(tokens[1]))/2\n",
    "    \n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "convert_sqft_to_num(\"2166\")\n",
    "\n",
    "convert_sqft_to_num(\"2100-2850\")\n",
    "\n",
    "convert_sqft_to_num(\"34.46Sq. Meter\t\")\n",
    "\n",
    "df4 = df3.copy()\n",
    "df4[\"total_sqft\"] = df4[\"total_sqft\"].apply(convert_sqft_to_num)\n",
    "# df4.head(10)\n",
    "\n",
    "# df4.iloc[30]\n",
    "\n",
    "# df4.shape\n",
    "\n",
    "# df4.loc[410]\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "df5 = df4.copy()\n",
    "\n",
    "# creating price_per_sqft column\n",
    "\n",
    "df5[\"price_per_sqft\"] = df5[\"price\"]*100000 / df5[\"total_sqft\"]\n",
    "# df5.head(10)\n",
    "\n",
    "# examining the location column\n",
    "\n",
    "# df5[\"location\"].unique()\n",
    "\n",
    "# len(df5[\"location\"].unique())\n",
    "\n",
    "df5[\"location\"] = df5[\"location\"].apply(lambda x : x.strip()) # remove trailing and leading space\n",
    "\n",
    "location_stats = df5.groupby(\"location\")['location'].agg(\"count\").sort_values(ascending = False)  # finding the count of unique locations\n",
    "# location_stats\n",
    "\n",
    "# len(location_stats[location_stats <= 10])\n",
    "\n",
    "location_stats_less_than_10 = location_stats[location_stats <= 10]\n",
    "# location_stats_less_than_10\n",
    "\n",
    "# making the location attribute \"other\" if the count of the location is <= 10\n",
    "df5[\"location\"] = df5[\"location\"].apply(lambda x : \"other\" if x in location_stats_less_than_10 else x)  \n",
    "# df5.head(10)\n",
    "\n",
    "len(df5[\"location\"].unique()) #now we have only 242 unique location\n",
    "\n",
    "## Outlier Removal\n",
    "\n",
    "# Outliers are data points which are not valid, may be error,or they may be valid \n",
    "# but can cause extreme variation in dataset values\n",
    "\n",
    "# we are finding the flats where size of a room in very small say less than 300 sqft\n",
    "# We are considering them anomaly\n",
    "\n",
    "# df5[df5[\"total_sqft\"] / df5[\"bhk\"] < 300].head(10)\n",
    "\n",
    "# df5.shape\n",
    "\n",
    "df6 = df5[~(df5[\"total_sqft\"] / df5[\"bhk\"] < 300)]  # removing those anomalies\n",
    "\n",
    "# df6.shape\n",
    "\n",
    "# checking the price_per_sqft column\n",
    "\n",
    "# df6[\"price_per_sqft\"].describe()\n",
    "\n",
    "def remove_pps_outliers(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby(\"location\"):\n",
    "        m = np.mean(subdf[\"price_per_sqft\"])\n",
    "        st = np.std(subdf[\"price_per_sqft\"])\n",
    "        \n",
    "        reduced_df = subdf[(subdf[\"price_per_sqft\"] > (m-st)) & (subdf[\"price_per_sqft\"] <= (m+st))]\n",
    "        df_out = pd.concat([df_out, reduced_df], ignore_index = True)\n",
    "    return df_out\n",
    "\n",
    "df7 = remove_pps_outliers(df6)\n",
    "\n",
    "# df7.shape\n",
    "\n",
    "def plot_scatter_chart(df, location):\n",
    "    bhk2 = df[(df[\"location\"] == location) & (df[\"bhk\"] == 2)]\n",
    "    bhk3 = df[(df[\"location\"] == location) & (df[\"bhk\"] == 3)]\n",
    "    \n",
    "    matplotlib.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "    plt.scatter(bhk2[\"total_sqft\"], bhk2[\"price\"], color=\"blue\", label=\"2 BHK\", s = 50)\n",
    "    plt.scatter(bhk3[\"total_sqft\"], bhk3[\"price\"], marker = \"+\", color=\"green\", label=\"3 BHK\", s = 50)\n",
    "    \n",
    "    plt.xlabel(\"Total Square Feet Area\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.title(location)\n",
    "    plt.legend()\n",
    "    \n",
    "# plot_scatter_chart(df7, \"Hebbal\")\n",
    "\n",
    "def remove_bhk_outliers(df):\n",
    "    exclude_indices = np.array([])\n",
    "    \n",
    "    for location, location_df in df.groupby(\"location\"):\n",
    "        bhk_stats = {}\n",
    "        for bhk, bhk_df in location_df.groupby(\"bhk\"):\n",
    "            bhk_stats[bhk] = {\n",
    "                \"mean\": np.mean(bhk_df[\"price_per_sqft\"]),\n",
    "                \"std\": np.std(bhk_df[\"price_per_sqft\"]),\n",
    "                \"count\": bhk_df.shape[0]\n",
    "            }\n",
    "            \n",
    "        for bhk, bhk_df in location_df.groupby(\"bhk\"):\n",
    "            stats = bhk_stats.get(bhk-1)\n",
    "            if stats and stats[\"count\"] > 5:\n",
    "                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df[\"price_per_sqft\"] < (stats[\"mean\"])].index.values)\n",
    "    return df.drop(exclude_indices, axis = \"index\")\n",
    "\n",
    "\n",
    "df8 = remove_bhk_outliers(df7)\n",
    "\n",
    "# df8.shape\n",
    "\n",
    "# plot_scatter_chart(df8, \"Hebbal\")\n",
    "\n",
    "# matplotlib.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "# plt.hist(df8[\"price_per_sqft\"], rwidth = 0.8)\n",
    "# plt.xlabel(\"Price Per Square Feet\")\n",
    "# plt.ylabel(\"Count\")\n",
    "\n",
    "# exploring bathroom features\n",
    "# df8[\"bath\"].unique()\n",
    "\n",
    "# df8[df8[\"bath\"] > 10]\n",
    "\n",
    "# plt.hist(df8[\"bath\"], rwidth = 0.8)\n",
    "# plt.xlabel(\"Number of bathrooms\")\n",
    "# plt.ylabel(\"Count\")\n",
    "\n",
    "#removing bathroom outliers (number of bathroom > no. of bedroom + 2)\n",
    "\n",
    "# df8[df8[\"bath\"] > df8[\"bhk\"] + 2]\n",
    "\n",
    "df9 = df8[df8[\"bath\"] < df8[\"bhk\"] + 2]\n",
    "\n",
    "# df9.shape\n",
    "\n",
    "df10 = df9.drop([\"size\", \"price_per_sqft\"], axis = \"columns\")\n",
    "\n",
    "# df10.head(10)\n",
    "\n",
    "# hot encoding the location attribute\n",
    "\n",
    "dummies = pd.get_dummies(df10[\"location\"])\n",
    "# dummies.head(5)\n",
    "\n",
    "df11 = pd.concat([df10, dummies.drop(\"other\", axis = \"columns\")], axis = \"columns\")\n",
    "# df11.head(5)\n",
    "\n",
    "df12 = df11.drop(\"location\", axis = \"columns\")\n",
    "# df12.head()\n",
    "\n",
    "# df12.shape\n",
    "\n",
    "# Building the Model\n",
    "X = df12.drop(\"price\", axis = \"columns\") #all independent variables\n",
    "# X.head()\n",
    "\n",
    "y = df12[\"price\"]\n",
    "# y.head()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_clf = LinearRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_clf.score(X_test, y_test)\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "cross_val_score(LinearRegression(), X, y, cv = cv)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "def find_best_model_using_gridsearchcv(X, y):\n",
    "    algos = {\n",
    "        'linear_regression': {\n",
    "            'model': LinearRegression(),\n",
    "            'params': {\n",
    "                'normalize': [True, False]\n",
    "            }\n",
    "        },\n",
    "        'lasso': {\n",
    "            'model': Lasso(),\n",
    "            'params': {\n",
    "                'alpha': [1, 2],\n",
    "                'selection': ['random', 'cyclic']\n",
    "            }\n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'criterion': ['mse', 'friedman_mse'],\n",
    "                'splitter': ['best', 'random']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    for algo_name, config in algos.items():\n",
    "        gs = GridSearchCV(config['model'], config['params'], cv = cv, return_train_score=False)\n",
    "        gs.fit(X, y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(scores, columns = [\"model\", \"best_score\", \"best_params\"])\n",
    "\n",
    "find_best_model_using_gridsearchcv(X, y)\n",
    "\n",
    "# clearly Linear regression is the winner here,with which we already train our model\n",
    "\n",
    "# X.columns\n",
    "\n",
    "# np.where(X.columns == \"1st Phase JP Nagar\")[0][0]\n",
    "\n",
    "def predict_price(location, sqft, bath, bhk):\n",
    "    loc_index = np.where(X.columns == location)[0][0]\n",
    "    \n",
    "    x = np.zeros(len(X.columns))\n",
    "    x[0] = sqft\n",
    "    x[1] = bath\n",
    "    x[2] = bhk\n",
    "    if loc_index >= 0:\n",
    "        x[loc_index] = 1\n",
    "    \n",
    "    return lr_clf.predict([x])[0]\n",
    "\n",
    "predict_price(\"1st Phase JP Nagar\", 1000, 2, 2)\n",
    "\n",
    "predict_price(\"1st Phase JP Nagar\", 1000, 2, 3)\n",
    "\n",
    "predict_price(\"1st Phase JP Nagar\", 1500, 5, 5)\n",
    "\n",
    "predict_price(\"Indira Nagar\", 1000, 2, 2)\n",
    "\n",
    "predict_price(\"Indira Nagar\", 1000, 3, 3)\n",
    "\n",
    "# exporting the model in a pickle file\n",
    "import pickle\n",
    "with open('bangalore_home_prices_model.pickle', 'wb') as f:\n",
    "    pickle.dump(lr_clf, f)\n",
    "\n",
    "# exporting the column information\n",
    "import json\n",
    "columns = {\n",
    "    'data_columns': [col.lower() for col in X.columns]\n",
    "}\n",
    "with open(\"columns.json\", \"w\") as f:\n",
    "    f.write(json.dumps(columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
